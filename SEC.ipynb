    "import re\n",
    "import base64\n",
    "import os\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from google.oauth2.credentials import Credentials\n",
    "from google.auth.transport.requests import Request\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from googleapiclient.discovery import build\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import joblib\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Download NLTK resources\n",
    "nltk.download('stopwords')\n",
    "\n",
    "class SpamClassifier:\n",
    "    def __init__(self):\n",
    "        self.pipeline = Pipeline([\n",
    "            ('vectorizer', TfidfVectorizer()),\n",
    "            ('classifier', RandomForestClassifier())\n",
    "        ])\n",
    "\n",
    "    def preprocess_text(self, text):\n",
    "        text = re.sub(r'\\W', ' ', text.lower())\n",
    "        return text\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        X_train = [self.preprocess_text(text) for text in X_train]\n",
    "        self.pipeline.fit(X_train, y_train)\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        X_test = [self.preprocess_text(text) for text in X_test]\n",
    "        return self.pipeline.predict(X_test)\n",
    "\n",
    "def create_spam_dataset():\n",
    "    spam_examples = [\n",
    "        \"Get a free iPhone now!\",\n",
    "        \"Congratulations! You've won $1,000,000!\",\n",
    "        \"Enlarge your bank account with this amazing opportunity!\",\n",
    "        \"Exclusive deals on luxury watches - limited time offer!\"\n",
    "    ]\n",
    "\n",
    "    non_spam_examples = [\n",
    "        \"Meeting tomorrow at 10 AM.\",\n",
    "        \"Reminder: Submit your project report by Friday.\",\n",
    "        \"Please find the attached document for your review.\",\n",
    "        \"Invitation to a webinar on data science trends.\"\n",
    "    ]\n",
    "\n",
    "    data = {'email': spam_examples + non_spam_examples, 'label': [1] * len(spam_examples) + [0] * len(non_spam_examples)}\n",
    "    df = pd.DataFrame(data).sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "    return df['email'].tolist(), df['label'].tolist()\n",
    "\n",
    "def fetch_emails(service):\n",
    "    results = service.users().messages().list(userId='me', labelIds=['INBOX'], q='is:unread').execute()\n",
    "    messages = results.get('messages', [])\n",
    "\n",
    "    if not messages:\n",
    "        print('No new emails found.')\n",
    "        return []\n",
    "\n",
    "    emails = []\n",
    "    for message in messages:\n",
    "        msg = service.users().messages().get(userId='me', id=message['id']).execute()\n",
    "        body = msg['payload']['body']['data']\n",
    "        decoded_body = base64.urlsafe_b64decode(body).decode('utf-8')\n",
    "        emails.append(decoded_body)\n",
    "\n",
    "    return emails\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Create and split the dataset\n",
    "    emails, labels = create_spam_dataset()\n",
    "    X_train, _, y_train, _ = train_test_split(emails, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train the spam classifier\n",
    "    spam_classifier = SpamClassifier()\n",
    "    \n",
    "    # Use SMOTE for oversampling to handle imbalanced data\n",
    "    smote = SMOTE(sampling_strategy='auto', random_state=42)\n",
    "    X_train_resampled, y_train_resampled = smote.fit_resample([X_train], y_train)\n",
    "    spam_classifier.train(X_train_resampled[0], y_train_resampled)\n",
    "\n",
    "    # Save the trained model to disk\n",
    "    joblib.dump(spam_classifier, 'spam_classifier_model.pkl')\n",
    "\n",
    "    # Set up the Gmail API\n",
    "    SCOPES = ['https://www.googleapis.com/auth/gmail.readonly']\n",
    "    creds = None\n",
    "\n",
    "    if os.path.exists('token.json'):\n",
    "        creds = Credentials.from_authorized_user_file('token.json')\n",
    "\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file(\n",
    "                'credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "\n",
    "        with open('token.json', 'w') as token:\n",
    "            token.write(creds.to_json())\n",
    "\n",
    "    # Create Gmail API service\n",
    "    service = build('gmail', 'v1', credentials=creds)\n",
    "\n",
    "    # Fetch unread emails\n",
    "    unread_emails = fetch_emails(service)\n",
    "\n",
    "    if not unread_emails:\n",
    "        print('No unread emails to classify.')\n",
    "    else:\n",
    "        # Load the trained spam classifier\n",
    "        spam_classifier = joblib.load('spam_classifier_model.pkl')\n",
    "\n",
    "        # Classify emails\n",
    "        predictions = spam_classifier.predict(unread_emails)\n",
    "\n",
    "        # Mark emails as spam or not spam (modify as needed)\n",
    "        for email, prediction in zip(unread_emails, predictions):\n",
    "            if prediction == 1:\n",
    "                print('Marking email as spam:')\n",
    "                print(email)\n",
    "                # Perform actions to mark email as spam (e.g., move to spam folder)\n",
    "\n",
    "            else:\n",
    "                print('Classified as not spam:')\n",
    "                print(email)\n",
    "                # Perform actions for non-spam emails (e.g., leave in the inbox)\n"

 

